{
	"name": "python new add samples_5",
	"properties": {
		"folder": {
			"name": "Sample Notebooks"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "78b203d6-8f9a-4c23-8b66-f9c79d4ac641"
			}
		},
		"metadata": {
			"saveOutput": true,
			"synapse_widget": "https://scq02goewttma9u3x6nv7upy.blob.core.windows.net:443/notebook/bdbj20220418ws/2b169b17-a4de-4760-b82c-69813d64b858/babaa492-ea08-404c-8961-ffd04a177443/metadata-synapse_widget/synapse_widget.json",
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"source": [
					"# Bankruptcy Prediction with LightGBM Classifier\r\n",
					""
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Introduction of LightGBM\n",
					"[LightGBM](https://github.com/Microsoft/LightGBM) is an open-source, distributed, high-performance gradient boosting framework with following advantages: \n",
					"-   Composability: LightGBM models can be incorporated into existing\n",
					"    SparkML Pipelines, and used for batch, streaming, and serving\n",
					"    workloads.\n",
					"-   Performance: LightGBM on Spark is 10-30% faster than SparkML on\n",
					"    the Higgs dataset, and achieves a 15% increase in AUC.  [Parallel\n",
					"    experiments](https://github.com/Microsoft/LightGBM/blob/master/docs/Experiments.rst#parallel-experiment)\n",
					"    have verified that LightGBM can achieve a linear speed-up by using\n",
					"    multiple machines for training in specific settings.\n",
					"-   Functionality: LightGBM offers a wide array of [tunable\n",
					"    parameters](https://github.com/Microsoft/LightGBM/blob/master/docs/Parameters.rst),\n",
					"    that one can use to customize their decision tree system. LightGBM on\n",
					"    Spark also supports new types of problems such as quantile regression.\n",
					"-   Cross platform：LightGBM on Spark is available on Spark (Scala) and PySpark (Python).\n",
					""
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"\n",
					"<img src=\"https://mmlspark.blob.core.windows.net/graphics/Documentation/bankruptcy image.png\" width=\"800\" style=\"float: center;\"/>\n",
					"\n",
					"In this example, we use LightGBM to build a classification model in order to predict bankruptcy."
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Read dataset\r\n",
					"\r\n",
					"Get a sample data of financial statements for 6819 companies, 220 represents bankrupted companies while 6599 firms are not bankrupted. "
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"dataset = spark.read.format(\"csv\")\\\n",
					"  .option(\"header\", True)\\\n",
					"  .load(\"wasbs://publicwasb@mmlspark.blob.core.windows.net/company_bankruptcy_prediction_data.csv\")"
				],
				"attachments": null,
				"execution_count": 1
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Exploratory data\r\n",
					"\r\n",
					"Look at the data and evaluate its suitability for use in a model."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"display(dataset.head(5))"
				],
				"attachments": null,
				"execution_count": 2
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": true
				},
				"source": [
					"# print dataset size\r\n",
					"print(\"Total number of records: \" + str(dataset.count()))"
				],
				"attachments": null,
				"execution_count": 3
			},
			{
				"cell_type": "code",
				"source": [
					"# convert features to double type\n",
					"from pyspark.sql.functions import col\n",
					"from pyspark.sql.types import DoubleType\n",
					"for colName in dataset.columns:\n",
					"  dataset = dataset.withColumn(colName, col(colName).cast(DoubleType()))\n",
					"print(\"Schema: \")\n",
					"dataset.printSchema()"
				],
				"attachments": null,
				"execution_count": 4
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Generation of testing and training data sets\r\n",
					"\r\n",
					"Simple split, 85% for training and 15% for testing the model. Playing with this ratio may result in different models.\r\n",
					""
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"# Split the dataset into train and test\n",
					"\n",
					"train, test = dataset.randomSplit([0.70, 0.30], seed=1)\n",
					"\n",
					"# Add featurizer to convert features to vector\n",
					"\n",
					"from pyspark.ml.feature import VectorAssembler\n",
					"feature_cols = dataset.columns[1:]\n",
					"featurizer = VectorAssembler(\n",
					"    inputCols=feature_cols,\n",
					"    outputCol='features'\n",
					")\n",
					"train_data = featurizer.transform(train)['Bankrupt?', 'features']\n",
					"test_data = featurizer.transform(test)['Bankrupt?', 'features']"
				],
				"attachments": null,
				"execution_count": 5
			},
			{
				"cell_type": "code",
				"source": [
					"# check if the data is unbalanced\r\n",
					"train_data.groupBy(\"Bankrupt?\").count().show()"
				],
				"attachments": null,
				"execution_count": 6
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Train the model\r\n",
					"Train the Classifier model."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"from mmlspark.lightgbm import LightGBMClassifier\n",
					"\n",
					"model = LightGBMClassifier(objective=\"binary\", featuresCol=\"features\", labelCol=\"Bankrupt?\", isUnbalance=True)\n",
					"model = model.fit(train_data)"
				],
				"attachments": null,
				"execution_count": 7
			},
			{
				"cell_type": "code",
				"source": [
					"from mmlspark.lightgbm import LightGBMClassificationModel\n",
					"model.saveNativeModel(\"/lgbmcmodel\")\n",
					"model = LightGBMClassificationModel.loadNativeModelFromFile(\"/lgbmcmodel\")"
				],
				"attachments": null,
				"execution_count": 8
			},
			{
				"cell_type": "code",
				"source": [
					"print(model.getFeatureImportances())"
				],
				"attachments": null,
				"execution_count": 9
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Model Performance Evaluation\r\n",
					"\r\n",
					"After training the model, we evaluate the performance of the model using the test set."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"predictions = model.transform(test_data)\n",
					"#predictions.limit(10).toPandas()"
				],
				"attachments": null,
				"execution_count": 10
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": true
				},
				"source": [
					"from mmlspark.train import ComputeModelStatistics\r\n",
					"\r\n",
					"# Compute model performance metrics\r\n",
					"metrics = ComputeModelStatistics(evaluationMetric=\"classification\", \r\n",
					"                                 labelCol=\"prediction\", \r\n",
					"                                 scoredLabelsCol=\"Bankrupt?\").transform(predictions)\r\n",
					"metrics.toPandas()"
				],
				"attachments": null,
				"execution_count": 11
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Clean up resources\r\n",
					"To ensure the Spark instance is shut down, end any connected sessions(notebooks). The pool shuts down when the **idle time** specified in the Apache Spark pool is reached. You can also select **stop session** from the status bar at the upper right of the notebook.\r\n",
					"\r\n",
					"![stopsession](https://adsnotebookrelease.blob.core.windows.net/adsnotebookrelease/adsnotebook/image/stopsession.png)"
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Next steps\r\n",
					"\r\n",
					"* [Check out Synapse sample notebooks](https://github.com/Azure-Samples/Synapse/tree/main/MachineLearning) \r\n",
					"* [MMLSpark GitHub Repo](https://github.com/Azure/mmlspark)"
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"# Boston house price prediction with Vowpal Wabbit, LightGBM and Spark MLlib\n",
					"\n",
					"This notebook shows how to build simple regression models by using \n",
					"[Vowpal Wabbit (VW)](https://github.com/VowpalWabbit/vowpal_wabbit) and \n",
					"[LightGBM](https://github.com/microsoft/LightGBM) with MMLSpark.\n",
					" We also compare the results with \n",
					" [Spark MLlib Linear Regression](https://spark.apache.org/docs/latest/ml-classification-regression.html#linear-regression)."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"import math\n",
					"from matplotlib.colors import ListedColormap, Normalize\n",
					"from matplotlib.cm import get_cmap\n",
					"import matplotlib.pyplot as plt\n",
					"from mmlspark.train import ComputeModelStatistics\n",
					"from mmlspark.vw import VowpalWabbitRegressor, VowpalWabbitFeaturizer\n",
					"from mmlspark.lightgbm import LightGBMRegressor\n",
					"import numpy as np\n",
					"import pandas as pd\n",
					"from pyspark.ml.feature import VectorAssembler\n",
					"from pyspark.ml.regression import LinearRegression\n",
					"from sklearn.datasets import load_boston"
				],
				"attachments": null,
				"execution_count": 12
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Prepare Dataset\n",
					"We use [*Boston house price* dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html) \n",
					". \n",
					"The data was collected in 1978 from Boston area and consists of 506 entries with 14 features including the value of homes. \n",
					"We use `sklearn.datasets` module to download it easily, then split the set into training and testing by 75/25."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"boston = load_boston()\n",
					"\n",
					"feature_cols = ['f' + str(i) for i in range(boston.data.shape[1])]\n",
					"header = ['target'] + feature_cols\n",
					"df = spark.createDataFrame(\n",
					"    pd.DataFrame(data=np.column_stack((boston.target, boston.data)), columns=header)\n",
					").repartition(1)\n",
					"print(\"Dataframe has {} rows\".format(df.count()))\n",
					"display(df.limit(10).toPandas())"
				],
				"attachments": null,
				"execution_count": 13
			},
			{
				"cell_type": "code",
				"source": [
					"train_data, test_data = df.randomSplit([0.75, 0.25], seed=42)\n",
					"train_data.cache()\n",
					"test_data.cache()"
				],
				"attachments": null,
				"execution_count": 14
			},
			{
				"cell_type": "markdown",
				"source": [
					"Following is the summary of the training set."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"display(train_data.summary().toPandas())"
				],
				"attachments": null,
				"execution_count": 15
			},
			{
				"cell_type": "markdown",
				"source": [
					"Plot feature distributions over different target values (house prices in our case)."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"features = train_data.columns[1:]\n",
					"values = train_data.drop('target').toPandas()\n",
					"ncols = 5\n",
					"nrows = math.ceil(len(features) / ncols)\n",
					"\n",
					"yy = [r['target'] for r in train_data.select('target').collect()]\n",
					"\n",
					"f, axes = plt.subplots(nrows, ncols, sharey=True, figsize=(30,10))\n",
					"f.tight_layout()\n",
					"\n",
					"for irow in range(nrows):\n",
					"    axes[irow][0].set_ylabel('target')\n",
					"    for icol in range(ncols):\n",
					"        try:\n",
					"            feat = features[irow*ncols + icol]\n",
					"            xx = values[feat]\n",
					"\n",
					"            axes[irow][icol].scatter(xx, yy, s=10, alpha=0.25)\n",
					"            axes[irow][icol].set_xlabel(feat)\n",
					"            axes[irow][icol].get_yaxis().set_ticks([])\n",
					"        except IndexError:\n",
					"            f.delaxes(axes[irow][icol])"
				],
				"attachments": null,
				"execution_count": 16
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Baseline - Spark MLlib Linear Regressor\n",
					"\n",
					"First, we set a baseline performance by using Linear Regressor in Spark MLlib."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"featurizer = VectorAssembler(\n",
					"    inputCols=feature_cols,\n",
					"    outputCol='features'\n",
					")\n",
					"lr_train_data = featurizer.transform(train_data)['target', 'features']\n",
					"lr_test_data = featurizer.transform(test_data)['target', 'features']\n",
					"display(lr_train_data.limit(10).toPandas())"
				],
				"attachments": null,
				"execution_count": 17
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"# By default, `maxIter` is 100. Other params you may want to change include: `regParam`, `elasticNetParam`, etc.\n",
					"lr = LinearRegression(\n",
					"    labelCol='target',\n",
					")\n",
					"\n",
					"lr_model = lr.fit(lr_train_data)\n",
					"lr_predictions = lr_model.transform(lr_test_data)\n",
					"\n",
					"display(lr_predictions.limit(10).toPandas())"
				],
				"attachments": null,
				"execution_count": 18
			},
			{
				"cell_type": "markdown",
				"source": [
					"We evaluate the prediction result by using `mmlspark.train.ComputeModelStatistics` which returns four metrics:\n",
					"* [MSE (Mean Squared Error)](https://en.wikipedia.org/wiki/Mean_squared_error)\n",
					"* [RMSE (Root Mean Squared Error)](https://en.wikipedia.org/wiki/Root-mean-square_deviation) = sqrt(MSE)\n",
					"* [R quared](https://en.wikipedia.org/wiki/Coefficient_of_determination)\n",
					"* [MAE (Mean Absolute Error)](https://en.wikipedia.org/wiki/Mean_absolute_error)"
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"metrics = ComputeModelStatistics(\n",
					"    evaluationMetric='regression',\n",
					"    labelCol='target',\n",
					"    scoresCol='prediction'\n",
					").transform(lr_predictions)\n",
					"\n",
					"results = metrics.toPandas()\n",
					"results.insert(0, 'model', ['Spark MLlib - Linear Regression'])\n",
					"display(results)"
				],
				"attachments": null,
				"execution_count": 19
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Vowpal Wabbit"
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"Perform VW-style feature hashing. Many types (numbers, string, bool, map of string to (number, string)) are supported."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"vw_featurizer = VowpalWabbitFeaturizer(\n",
					"    inputCols=feature_cols,\n",
					"    outputCol='features',\n",
					")\n",
					"vw_train_data = vw_featurizer.transform(train_data)['target', 'features']\n",
					"vw_test_data = vw_featurizer.transform(test_data)['target', 'features']\n",
					"display(vw_train_data.limit(10).toPandas())"
				],
				"attachments": null,
				"execution_count": 20
			},
			{
				"cell_type": "markdown",
				"source": [
					"See [VW wiki](https://github.com/vowpalWabbit/vowpal_wabbit/wiki/Command-Line-Arguments) for command line arguments."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"# Use the same number of iterations as Spark MLlib's Linear Regression (=100)\n",
					"args = \"--holdout_off --loss_function quantile -l 7 -q :: --power_t 0.3\"\n",
					"vwr = VowpalWabbitRegressor(\n",
					"    labelCol='target',\n",
					"    args=args,\n",
					"    numPasses=100,\n",
					")\n",
					"\n",
					"# To reduce number of partitions (which will effect performance), use `vw_train_data.repartition(1)`\n",
					"vw_train_data_2 = vw_train_data.repartition(1).cache()\n",
					"print(vw_train_data_2.count())\n",
					"vw_model = vwr.fit(vw_train_data_2.repartition(1))\n",
					"vw_predictions = vw_model.transform(vw_test_data)\n",
					"\n",
					"display(vw_predictions.limit(10).toPandas())"
				],
				"attachments": null,
				"execution_count": 21
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"metrics = ComputeModelStatistics(\n",
					"    evaluationMetric='regression',\n",
					"    labelCol='target',\n",
					"    scoresCol='prediction'\n",
					").transform(vw_predictions)\n",
					"\n",
					"vw_result = metrics.toPandas()\n",
					"vw_result.insert(0, 'model', ['Vowpal Wabbit'])\n",
					"results = results.append(\n",
					"    vw_result,\n",
					"    ignore_index=True\n",
					")\n",
					"display(results)"
				],
				"attachments": null,
				"execution_count": 22
			},
			{
				"cell_type": "markdown",
				"source": [
					"## LightGBM"
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"lgr = LightGBMRegressor(\n",
					"    objective='quantile',\n",
					"    alpha=0.2,\n",
					"    learningRate=0.3,\n",
					"    numLeaves=31,\n",
					"    labelCol='target',\n",
					"    numIterations=100,\n",
					")\n",
					"\n",
					"# Using one partition since the training dataset is very small\n",
					"repartitioned_data = lr_train_data.repartition(1).cache()\n",
					"print(repartitioned_data.count())\n",
					"lg_model = lgr.fit(repartitioned_data)\n",
					"lg_predictions = lg_model.transform(lr_test_data)\n",
					"\n",
					"display(lg_predictions.limit(10).toPandas())"
				],
				"attachments": null,
				"execution_count": 23
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"metrics = ComputeModelStatistics(\n",
					"    evaluationMetric='regression',\n",
					"    labelCol='target',\n",
					"    scoresCol='prediction'\n",
					").transform(lg_predictions)\n",
					"\n",
					"lg_result = metrics.toPandas()\n",
					"lg_result.insert(0, 'model', ['LightGBM'])\n",
					"results = results.append(\n",
					"    lg_result,\n",
					"    ignore_index=True\n",
					")\n",
					"display(results)"
				],
				"attachments": null,
				"execution_count": 24
			},
			{
				"cell_type": "markdown",
				"source": [
					"Following figure shows the actual-vs.-prediction graphs of the results:\n",
					"\n",
					"<img width=\"1102\" alt=\"lr-vw-lg\" src=\"https://user-images.githubusercontent.com/42475935/64071975-4c3e9600-cc54-11e9-8b1f-9a1ee300f445.png\">"
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"cmap = get_cmap('YlOrRd')\n",
					"\n",
					"target = np.array(test_data.select('target').collect()).flatten()\n",
					"model_preds = [\n",
					"    (\"Spark MLlib Linear Regression\", lr_predictions),\n",
					"    (\"Vowpal Wabbit\", vw_predictions),\n",
					"    (\"LightGBM\", lg_predictions)\n",
					"]"
				],
				"attachments": null,
				"execution_count": 25
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": true
				},
				"source": [
					"f, axes = plt.subplots(1, len(model_preds), sharey=True, figsize=(18, 6))\r\n",
					"f.tight_layout()\r\n",
					"\r\n",
					"for i, (model_name, preds) in enumerate(model_preds):\r\n",
					"    preds = np.array(preds.select('prediction').collect()).flatten()\r\n",
					"    err = np.absolute(preds - target)\r\n",
					"\r\n",
					"    norm = Normalize()\r\n",
					"    clrs = cmap(np.asarray(norm(err)))[:, :-1]\r\n",
					"    axes[i].scatter(preds, target, s=60, c=clrs, edgecolors='#888888', alpha=0.75)\r\n",
					"    axes[i].plot((0, 60), (0, 60), linestyle='--', color='#888888')\r\n",
					"    axes[i].set_xlabel('Predicted values')\r\n",
					"    if i ==0:\r\n",
					"        axes[i].set_ylabel('Actual values')\r\n",
					"    axes[i].set_title(model_name)\r\n",
					"plt.show()"
				],
				"attachments": null,
				"execution_count": 26
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Clean up resources\r\n",
					"To ensure the Spark instance is shut down, end any connected sessions(notebooks). The pool shuts down when the **idle time** specified in the Apache Spark pool is reached. You can also select **stop session** from the status bar at the upper right of the notebook.\r\n",
					"\r\n",
					"![stopsession](https://adsnotebookrelease.blob.core.windows.net/adsnotebookrelease/adsnotebook/image/stopsession.png)"
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Next steps\r\n",
					"\r\n",
					"* [Check out Synapse sample notebooks](https://github.com/Azure-Samples/Synapse/tree/main/MachineLearning) \r\n",
					"* [MMLSpark GitHub Repo](https://github.com/Azure/mmlspark)"
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"# Quantile Regression for Drug Discovery with LightGBM Regressor"
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Introduction of LightGBM\n",
					"[LightGBM](https://github.com/Microsoft/LightGBM) is an open-source, distributed, high-performance gradient boosting framework with following advantages: \n",
					"-   Composability: LightGBM models can be incorporated into existing\n",
					"    SparkML Pipelines, and used for batch, streaming, and serving\n",
					"    workloads.\n",
					"-   Performance: LightGBM on Spark is 10-30% faster than SparkML on\n",
					"    the Higgs dataset, and achieves a 15% increase in AUC.  [Parallel\n",
					"    experiments](https://github.com/Microsoft/LightGBM/blob/master/docs/Experiments.rst#parallel-experiment)\n",
					"    have verified that LightGBM can achieve a linear speed-up by using\n",
					"    multiple machines for training in specific settings.\n",
					"-   Functionality: LightGBM offers a wide array of [tunable\n",
					"    parameters](https://github.com/Microsoft/LightGBM/blob/master/docs/Parameters.rst),\n",
					"    that one can use to customize their decision tree system. LightGBM on\n",
					"    Spark also supports new types of problems such as quantile regression.\n",
					"-   Cross platform：LightGBM on Spark is available on Spark (Scala) and PySpark (Python)."
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"<img src=\"https://mmlspark.blob.core.windows.net/graphics/Documentation/drug.png\" width=\"800\" style=\"float: center;\"/>\n",
					"\n",
					"In this example, we use LightGBM quantile regressor on the Triazines dataset."
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Read dataset"
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"triazines = spark.read.format(\"libsvm\").load(\"wasbs://publicwasb@mmlspark.blob.core.windows.net/triazines.scale.svmlight\")"
				],
				"attachments": null,
				"execution_count": 27
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Exploratory data"
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"# print some basic info\n",
					"print(\"records read: \" + str(triazines.count()))\n",
					"print(\"Schema: \")\n",
					"triazines.printSchema()\n",
					"triazines.limit(10).toPandas()"
				],
				"attachments": null,
				"execution_count": 28
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Generation of testing and training data sets\r\n",
					"\r\n",
					"Simple split, 85% for training and 15% for testing the model. Playing with this ratio may result in different models."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"train, test = triazines.randomSplit([0.85, 0.15], seed=1)"
				],
				"attachments": null,
				"execution_count": 29
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Train the model\r\n",
					"Train the quantile regressor on the training data."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"from mmlspark.lightgbm import LightGBMRegressor\n",
					"model = LightGBMRegressor(objective='quantile',\n",
					"                          alpha=0.2,\n",
					"                          learningRate=0.3,\n",
					"                          numLeaves=31).fit(train)"
				],
				"attachments": null,
				"execution_count": 30
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": true
				},
				"source": [
					"# Save and load LightGBM to a file using the LightGBM native representation\r\n",
					"\r\n",
					"from mmlspark.lightgbm import LightGBMRegressionModel\r\n",
					"model.saveNativeModel(\"/mymodel\")\r\n",
					"model = LightGBMRegressionModel.loadNativeModelFromFile(\"/mymodel\")"
				],
				"attachments": null,
				"execution_count": 31
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": true
				},
				"source": [
					"# View the feature importances of the trained model\r\n",
					"\r\n",
					"print(model.getFeatureImportances())"
				],
				"attachments": null,
				"execution_count": 32
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Model performance evaluation\r\n",
					"\r\n",
					"After training the model, we evaluate the performance of the model using the test set."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"scoredData = model.transform(test)\n",
					"scoredData.limit(10).toPandas()"
				],
				"attachments": null,
				"execution_count": 33
			},
			{
				"cell_type": "code",
				"source": [
					"# Compute metrics using ComputeModelStatistics\n",
					"\n",
					"from mmlspark.train import ComputeModelStatistics\n",
					"metrics = ComputeModelStatistics(evaluationMetric='regression',\n",
					"                                 labelCol='label',\n",
					"                                 scoresCol='prediction') \\\n",
					"            .transform(scoredData)\n",
					"metrics.toPandas()"
				],
				"attachments": null,
				"execution_count": 34
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Clean up resources\r\n",
					"To ensure the Spark instance is shut down, end any connected sessions(notebooks). The pool shuts down when the **idle time** specified in the Apache Spark pool is reached. You can also select **stop session** from the status bar at the upper right of the notebook.\r\n",
					"\r\n",
					"![stopsession](https://adsnotebookrelease.blob.core.windows.net/adsnotebookrelease/adsnotebook/image/stopsession.png)"
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Next steps\r\n",
					"\r\n",
					"* [Check out Synapse sample notebooks](https://github.com/Azure-Samples/Synapse/tree/main/MachineLearning) \r\n",
					"* [MMLSpark GitHub Repo](https://github.com/Azure/mmlspark)"
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"# Twitter Sentiment Classification using Vowpal Wabbit in Microsoft Machine Learning for Apache Spark\n",
					"\n",
					"In this example, we show how to build a sentiment classification model using [Vowpal Wabbit (VW)](https://github.com/Azure/mmlspark/blob/master/docs/vw.md) in MMLSpark. The data set we use to train and evaluate the model is [Sentiment140](http://help.sentiment140.com/for-students/?source=post_page---------------------------) twitter data. First, we import a few packages that we need."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"import os\n",
					"import re\n",
					"import urllib.request\n",
					"import numpy as np\n",
					"import pandas as pd\n",
					"from zipfile import ZipFile\n",
					"from bs4 import BeautifulSoup\n",
					"from pyspark.sql.functions import udf, rand, when, col\n",
					"from pyspark.sql.types import StructType, StructField, DoubleType, StringType\n",
					"from pyspark.ml import Pipeline\n",
					"from pyspark.ml.feature import CountVectorizer, RegexTokenizer\n",
					"from mmlspark.vw import VowpalWabbitClassifier\n",
					"from mmlspark.train import ComputeModelStatistics\n",
					"from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
					"import matplotlib.pyplot as plt"
				],
				"attachments": null,
				"execution_count": 35
			},
			{
				"cell_type": "code",
				"source": [
					"# URL to download the sentiment140 dataset and data file names\n",
					"DATA_URL = \"http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip\"\n",
					"TRAIN_FILENAME = \"training.1600000.processed.noemoticon.csv\"\n",
					"TEST_FILENAME = \"testdata.manual.2009.06.14.csv\"\n",
					"# Folder for storing the downloaded data\n",
					"DATA_FOLDER = \"data\"\n",
					"# Data column names\n",
					"COL_NAMES = [\"label\", \"id\", \"date\", \"query_string\", \"user\", \"text\"]\n",
					"# Text encoding type of the data\n",
					"ENCODING = \"iso-8859-1\""
				],
				"attachments": null,
				"execution_count": 36
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Data Preparation\n",
					"\n",
					"We use [Sentiment140](http://help.sentiment140.com/for-students/?source=post_page---------------------------) twitter data which originated from a Standford research project to train and evaluate VW classification model on Spark. The same dataset has been used in a previous [Azure Machine Learning sample](https://github.com/Azure-Samples/MachineLearningSamples-TwitterSentimentPrediction) on twitter sentiment prediction. Before using the data to build the classification model, we first download and clean up the data."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"def download_data(url, data_folder=DATA_FOLDER, filename=\"downloaded_data.zip\"):\n",
					"    \"\"\"Download and extract data from url\"\"\"\n",
					"    \n",
					"    data_dir = \"./\" + DATA_FOLDER\n",
					"    if not os.path.exists(data_dir): os.makedirs(data_dir)\n",
					"    downloaded_filepath = os.path.join(data_dir, filename)\n",
					"    print(\"Downloading data...\")\n",
					"    urllib.request.urlretrieve(url, downloaded_filepath)\n",
					"    print(\"Extracting data...\")\n",
					"    zipfile = ZipFile(downloaded_filepath)\n",
					"    zipfile.extractall(data_dir)\n",
					"    zipfile.close()\n",
					"    print(\"Finished data downloading and extraction.\")\n",
					"    \n",
					"download_data(DATA_URL)"
				],
				"attachments": null,
				"execution_count": 37
			},
			{
				"cell_type": "markdown",
				"source": [
					"Let's read the training data into a Spark DataFrame."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"df_train = pd.read_csv(os.path.join(\".\", DATA_FOLDER, TRAIN_FILENAME), \n",
					"                       header=None, names=COL_NAMES, encoding=ENCODING)\n",
					"df_train = spark.createDataFrame(df_train, verifySchema=False)"
				],
				"attachments": null,
				"execution_count": 38
			},
			{
				"cell_type": "markdown",
				"source": [
					"We can take a look at the training data and check how many samples it has. We should see that there are 1.6 million samples in the training data. There are 6 fields in the training data:\n",
					"* label: the sentiment of the tweet (0.0 = negative, 2.0 = neutral, 4.0 = positive)\n",
					"* id: the id of the tweet\n",
					"* date: the date of the tweet\n",
					"* query_string: The query used to extract the data. If there is no query, then this value is NO_QUERY.\n",
					"* user: the user that tweeted\n",
					"* text: the text of the tweet"
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"df_train.limit(10).toPandas()"
				],
				"attachments": null,
				"execution_count": 39
			},
			{
				"cell_type": "code",
				"source": [
					"print(\"Number of training samples: \", df_train.count())"
				],
				"attachments": null,
				"execution_count": 40
			},
			{
				"cell_type": "markdown",
				"source": [
					"Before training the model, we randomly permute the data to mix negative and positive samples. This is helpful for properly training online learning algorithms like VW. To speed up model training, we use a subset of the data to train the model. If training with the full training set, typically you will see better performance of the model on the test set. "
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"df_train = df_train.orderBy(rand()) \\\n",
					"                   .limit(100000) \\\n",
					"                   .withColumn(\"label\", when(col(\"label\") > 0, 1.0).otherwise(0.0)) \\\n",
					"                   .select([\"label\", \"text\"])"
				],
				"attachments": null,
				"execution_count": 41
			},
			{
				"cell_type": "markdown",
				"source": [
					"## VW MMLSpark Training\n",
					"\n",
					"Now we are ready to define a pipeline which consists of feture engineering steps and the VW model."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"# Specify featurizers\n",
					"tokenizer = RegexTokenizer(inputCol=\"text\",\n",
					"                           outputCol=\"words\")\n",
					"\n",
					"count_vectorizer = CountVectorizer(inputCol=\"words\",\n",
					"                                   outputCol=\"features\")\n",
					"\n",
					"# Define VW classification model\n",
					"args = \"--loss_function=logistic --quiet --holdout_off\"\n",
					"vw_model = VowpalWabbitClassifier(featuresCol=\"features\", \n",
					"                                  labelCol=\"label\", \n",
					"                                  args=args, \n",
					"                                  numPasses=10)\n",
					"\n",
					"# Create a pipeline\n",
					"vw_pipeline = Pipeline(stages=[tokenizer, count_vectorizer, vw_model])"
				],
				"attachments": null,
				"execution_count": 42
			},
			{
				"cell_type": "markdown",
				"source": [
					"With the prepared training data, we can fit the model pipeline as follows."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"vw_trained = vw_pipeline.fit(df_train)"
				],
				"attachments": null,
				"execution_count": 43
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Model Performance Evaluation\n",
					"\n",
					"After training the model, we evaluate the performance of the model using the test set which is manually labeled."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"df_test = pd.read_csv(os.path.join(\".\", DATA_FOLDER, TEST_FILENAME), \n",
					"                       header=None, names=COL_NAMES, encoding=ENCODING)\n",
					"df_test = spark.createDataFrame(df_test, verifySchema=False)"
				],
				"attachments": null,
				"execution_count": 44
			},
			{
				"cell_type": "markdown",
				"source": [
					"We only use positive and negative tweets in the test set to evaluate the model, since our model is a binary classification model trained with only positive and negative tweets."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"print(\"Number of test samples before filtering: \", df_test.count())\n",
					"df_test = df_test.filter(col(\"label\") != 2.0) \\\n",
					"                 .withColumn(\"label\", when(col(\"label\") > 0, 1.0).otherwise(0.0)) \\\n",
					"                 .select([\"label\", \"text\"])\n",
					"print(\"Number of test samples after filtering: \", df_test.count())"
				],
				"attachments": null,
				"execution_count": 45
			},
			{
				"cell_type": "code",
				"source": [
					"# Make predictions\n",
					"predictions = vw_trained.transform(df_test)\n",
					"predictions.limit(10).toPandas()"
				],
				"attachments": null,
				"execution_count": 46
			},
			{
				"cell_type": "code",
				"source": [
					"# Compute model performance metrics\n",
					"metrics = ComputeModelStatistics(evaluationMetric=\"classification\", \n",
					"                                 labelCol=\"label\", \n",
					"                                 scoredLabelsCol=\"prediction\").transform(predictions)\n",
					"metrics.toPandas()"
				],
				"attachments": null,
				"execution_count": 47
			},
			{
				"cell_type": "code",
				"source": [
					"# Utility class for plotting ROC curve (https://stackoverflow.com/questions/52847408/pyspark-extract-roc-curve)\n",
					"class CurveMetrics(BinaryClassificationMetrics):\n",
					"    def __init__(self, *args):\n",
					"        super(CurveMetrics, self).__init__(*args)\n",
					"\n",
					"    def get_curve(self, method):\n",
					"        rdd = getattr(self._java_model, method)().toJavaRDD()\n",
					"        points = []\n",
					"        for row in rdd.collect():\n",
					"            points += [(float(row._1()), float(row._2()))]\n",
					"        return points\n",
					"\n",
					"preds = predictions.select(\"label\", \"probability\") \\\n",
					"                   .rdd.map(lambda row: (float(row[\"probability\"][1]), float(row[\"label\"])))\n",
					"roc_points = CurveMetrics(preds).get_curve(\"roc\")\n",
					"\n",
					"# Plot ROC curve\n",
					"fig = plt.figure()\n",
					"x_val = [x[0] for x in roc_points]\n",
					"y_val = [x[1] for x in roc_points]\n",
					"plt.title(\"ROC curve on test set\")\n",
					"plt.xlabel(\"False positive rate\")\n",
					"plt.ylabel(\"True positive rate\")\n",
					"plt.plot(x_val, y_val)\n",
					"\n",
					"# display(fig)\n",
					"plt.show()"
				],
				"attachments": null,
				"execution_count": 48
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Clean up resources\r\n",
					"To ensure the Spark instance is shut down, end any connected sessions(notebooks). The pool shuts down when the **idle time** specified in the Apache Spark pool is reached. You can also select **stop session** from the status bar at the upper right of the notebook.\r\n",
					"\r\n",
					"![stopsession](https://adsnotebookrelease.blob.core.windows.net/adsnotebookrelease/adsnotebook/image/stopsession.png)"
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Next steps\r\n",
					"\r\n",
					"* [Check out Synapse sample notebooks](https://github.com/Azure-Samples/Synapse/tree/main/MachineLearning) \r\n",
					"* [MMLSpark GitHub Repo](https://github.com/Azure/mmlspark)"
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nbsphinx": "hidden"
				},
				"source": [
					"**This notebook sample is based on the official [Jupyter Widgets sample notebook `Widget Basics.ipynb`](https://github.com/jupyter-widgets/ipywidgets/blob/7.x/docs/source/examples/Widget%20Basics.ipynb)\r\n",
					".** Edit this cell to see the full license content.\r\n",
					"\r\n",
					"<!--\r\n",
					"Copyright (c) 2015 Project Jupyter Contributors\r\n",
					"All rights reserved.\r\n",
					"\r\n",
					"Redistribution and use in source and binary forms, with or without\r\n",
					"modification, are permitted provided that the following conditions are met:\r\n",
					"\r\n",
					"1. Redistributions of source code must retain the above copyright notice, this\r\n",
					"   list of conditions and the following disclaimer.\r\n",
					"\r\n",
					"2. Redistributions in binary form must reproduce the above copyright notice,\r\n",
					"   this list of conditions and the following disclaimer in the documentation\r\n",
					"   and/or other materials provided with the distribution.\r\n",
					"\r\n",
					"3. Neither the name of the copyright holder nor the names of its\r\n",
					"   contributors may be used to endorse or promote products derived from\r\n",
					"   this software without specific prior written permission.\r\n",
					"\r\n",
					"THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\r\n",
					"AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\r\n",
					"IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\r\n",
					"DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\r\n",
					"FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\r\n",
					"DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\r\n",
					"SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\r\n",
					"CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\r\n",
					"OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\r\n",
					"OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\r\n",
					"-->"
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**Synapse Studio users**: Now you can consume Jupyter Widgets in Synapse Studio (with \"Preview Features\" turned on). Since it's a Python library, you will need to consume it in PySpark environment.\r\n",
					"To go through this sample, please create a new notebook from the sample, then execute the code cells one by one with \"Run\" button or `Shift+Enter` shortcut keys.\r\n",
					"\r\n",
					"See https://go.microsoft.com/fwlink/?linkid=2170793 for general introduction as well as known limitations on the Jupyter Widgets support in Synapse Studio."
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"# Simple Widget Introduction"
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"## What are widgets?"
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"slideshow": {
						"slide_type": "slide"
					}
				},
				"source": [
					"Widgets are eventful python objects that have a representation in the browser, often as a control like a slider, textbox, etc."
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"## What can they be used for?"
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"slideshow": {
						"slide_type": "slide"
					}
				},
				"source": [
					"You can use widgets to build **interactive GUIs** for your notebooks.  \n",
					"You can also use widgets to **synchronize stateful and stateless information** between Python and JavaScript."
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Using widgets  "
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"slideshow": {
						"slide_type": "slide"
					}
				},
				"source": [
					"To use the widget framework, you need to import `ipywidgets`."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"import ipywidgets as widgets\r\n",
					"widgets.__version__"
				],
				"attachments": null,
				"execution_count": 49
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"slideshow": {
						"slide_type": "slide"
					}
				},
				"source": [
					"### repr"
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"Widgets have their own display `repr` which allows them to be displayed using IPython's display framework.  Constructing and returning an `IntSlider` automatically displays the widget (as seen below).  Widgets are displayed inside the output area below the code cell. Clearing cell output will also remove the widget."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"widgets.IntSlider()"
				],
				"attachments": null,
				"execution_count": 50
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"slideshow": {
						"slide_type": "slide"
					}
				},
				"source": [
					"### display()"
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"You can also explicitly display the widget using `display(...)`.\r\n",
					"\r\n",
					"**Synapse Studio users**:\r\n",
					"* Usually you do not need to import `display` function manually from `IPython.display` package. The pre-imported global `display(d)` function now also accepts `Widget` instance as first parameter (`d`). Just note that it does not support more than 1 arguments. If you want to display 2 Widgets respectively, call `display` twice.\r\n",
					"* In case you have already imported `display` function from IPython, you can always use the following statement to restore the global `display` function provided by Synapse Studio, if necessary (e.g. when you want to display Spark `DataFrame`).\r\n",
					"```python\r\n",
					"from notebookutils import display\r\n",
					"```"
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"# pre-imported `display` already supports Widget. No need to import from IPyton.\n",
					"# from IPython.display import display\n",
					"w = widgets.IntSlider()\n",
					"display(w)"
				],
				"attachments": null,
				"execution_count": 51
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"slideshow": {
						"slide_type": "slide"
					}
				},
				"source": [
					"### Multiple display() calls"
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"If you display the same widget twice, the displayed instances in the front-end will remain in sync with each other.  Try dragging the slider below and watch the slider above."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"display(w)"
				],
				"attachments": null,
				"execution_count": 52
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Why does displaying the same widget twice work?"
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"slideshow": {
						"slide_type": "slide"
					}
				},
				"source": [
					"Widgets are represented in the back-end by a single object.  Each time a widget is displayed, a new representation of that same object is created in the front-end.  These representations are called views.\n",
					"\n",
					"![Kernel & front-end diagram](https://ipywidgets.readthedocs.io/en/7.x/_images/WidgetModelView.png)"
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"slideshow": {
						"slide_type": "slide"
					}
				},
				"source": [
					"### Closing widgets"
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"You can close a widget by calling its `close()` method."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"display(w)"
				],
				"attachments": null,
				"execution_count": 53
			},
			{
				"cell_type": "code",
				"source": [
					"w.close()"
				],
				"attachments": null,
				"execution_count": 54
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Widget properties"
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"slideshow": {
						"slide_type": "slide"
					}
				},
				"source": [
					"All of the IPython widgets share a similar naming scheme.  To read the value of a widget, you can query its `value` property."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"w = widgets.IntSlider()\n",
					"display(w)"
				],
				"attachments": null,
				"execution_count": 55
			},
			{
				"cell_type": "code",
				"source": [
					"w.value"
				],
				"attachments": null,
				"execution_count": 56
			},
			{
				"cell_type": "markdown",
				"source": [
					"Similarly, to set a widget's value, you can set its `value` property."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"w.value = 100"
				],
				"attachments": null,
				"execution_count": 57
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"slideshow": {
						"slide_type": "slide"
					}
				},
				"source": [
					"### Keys"
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"In addition to `value`, most widgets share `keys`, `description`, and `disabled`.  To see the entire list of synchronized, stateful properties of any specific widget, you can query the `keys` property."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"w.keys"
				],
				"attachments": null,
				"execution_count": 58
			},
			{
				"cell_type": "markdown",
				"source": [
					"### Shorthand for setting the initial values of widget properties"
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"slideshow": {
						"slide_type": "slide"
					}
				},
				"source": [
					"While creating a widget, you can set some or all of the initial values of that widget by defining them as keyword arguments in the widget's constructor (as seen below)."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"widgets.Text(value='Hello World!', disabled=True)"
				],
				"attachments": null,
				"execution_count": 59
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Linking two similar widgets"
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"slideshow": {
						"slide_type": "slide"
					}
				},
				"source": [
					"If you need to display the same value two different ways, you'll have to use two different widgets. Instead of attempting to manually synchronize the values of the two widgets, you can use the `link`  or `jslink` function to link two properties together (the difference between these is discussed in [Widget Events](https://ipywidgets.readthedocs.io/en/7.x/examples/Widget%20Events.html)).  Below, the values of two widgets are linked together.\r\n",
					"\r\n",
					"**Synapse Studio users**: `jslink` is not supported yet. As a workaround, use `link`."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"a = widgets.FloatText()\n",
					"b = widgets.FloatSlider()\n",
					"display(a)\n",
					"display(b)\n",
					"\n",
					"# `jslink` is not supported in Synapse Studio yet. Ue `link` instead.\n",
					"# mylink = widgets.jslink((a, 'value'), (b, 'value'))\n",
					"mylink = widgets.link((a, 'value'), (b, 'value'))"
				],
				"attachments": null,
				"execution_count": 60
			},
			{
				"cell_type": "markdown",
				"source": [
					"### Unlinking widgets"
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"slideshow": {
						"slide_type": "slide"
					}
				},
				"source": [
					"Unlinking the widgets is simple.  All you have to do is call `.unlink` on the link object.  Try changing one of the widgets above after unlinking to see that they can be independently changed."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"mylink.unlink()"
				],
				"attachments": null,
				"execution_count": 61
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nbsphinx": "hidden"
				},
				"source": [
					"## Next steps\r\n",
					"\r\n",
					"You can find more examples from the official [Jupyter Widgets documentation](https://ipywidgets.readthedocs.io/en/7.x/index.html), including\r\n",
					"* [Widget List](https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20List.html)\r\n",
					"* [Widget Events](https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20Events.html)\r\n",
					"* [Widget Styling](https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20Styling.html)\r\n",
					"* and more!"
				],
				"attachments": null
			}
		]
	}
}