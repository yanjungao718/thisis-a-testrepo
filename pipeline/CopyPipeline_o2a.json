{
	"name": "CopyPipeline_o2a",
	"properties": {
		"activities": [
			{
				"name": "Copy_o2a",
				"type": "Copy",
				"dependsOn": [],
				"policy": {
					"timeout": "7.00:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [
					{
						"name": "Source",
						"value": "default/synapse/workspaces/bigdataqa211206ext/batchjobs/Spark job definition 1/copy_opendataset_to_spark_table.py"
					},
					{
						"name": "Destination",
						"value": "default//test"
					}
				],
				"typeProperties": {
					"source": {
						"type": "DelimitedTextSource",
						"storeSettings": {
							"type": "AzureBlobFSReadSettings",
							"recursive": true,
							"enablePartitionDiscovery": false
						},
						"formatSettings": {
							"type": "DelimitedTextReadSettings",
							"skipLineCount": 8
						}
					},
					"sink": {
						"type": "DelimitedTextSink",
						"storeSettings": {
							"type": "AzureBlobFSWriteSettings"
						},
						"formatSettings": {
							"type": "DelimitedTextWriteSettings",
							"quoteAllText": true,
							"fileExtension": ".txt"
						}
					},
					"enableStaging": false,
					"validateDataConsistency": false
				},
				"inputs": [
					{
						"referenceName": "SourceDataset_o2a",
						"type": "DatasetReference"
					}
				],
				"outputs": [
					{
						"referenceName": "DestinationDataset_o2a",
						"type": "DatasetReference"
					}
				]
			}
		],
		"annotations": []
	}
}